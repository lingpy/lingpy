# Basic namespaces
cogid	int	cognateid,cogid,cognateset
counterpart	str	entry,counterpart,orthography,forminsource
doculect	str	language,doculect,dialect,taxon,languages,counterpart_doculect,taxa
concept	str	gloss,concept,concepts
iso	str	iso,isocode
tokens	lambda x:x.split(" ")	tokens,tokenized_counterpart,ipatokens
alignment	lambda x:x.split(" ")	alignment,alignments
ipa	str	word,ipa,words
ortho_parse	lambda x:x.split(" ")[1:-1]	orthography_tokens,tokenized_counterpart,op_tokens

# specific names for alignments
conceptid	int	conceptid

# Specific namespaces for LexStat
sonars	lambda x:[int(s) for s in x.split(" ")]	sonars
prostrings	str	prostrings
numbers	lambda x:x.split(" ")	numbers
langid	str	langid
classes	str	classes
weights	lambda x:[float(y) for y in x.split(' ')]	weights
scaid	int	scaid
lexstatid	int	lexstatid
editid	int	editid
turchinid	int	turchinid
fuzzyid	lambda x:[int(s) for s in x.split(" ")]	fuzzyid

# New namespaces for patchy cognates
patchyid	int	patchyid
papid	int	papid
seedid	int	seedid
customid	int	customid

# New namespaces for makrocomparison
makroid	int	makroid
mikroid	int	mikroid
mikro_entries	lambda x: [int(i) for i in x.split(" ")]	mikro_entries

# New namespaces for partial cognacy
clusterid	int	clusterid
clusterformat	lambda x: [int(i) for i in x.split(" ")]	clusterformat
morphemes	lambda x: x.split(" ")	morphemes
palignment	lambda x: x.split(" ")	pca,palignment,partial_cognate_alignment
pcogsets	lambda x: [int(i) for i in x.split(" ")]	partial_cognate_sets,pcogset,pcs
partialid	lambda x:[int(s) for s in x.split(" ")]	partialid

